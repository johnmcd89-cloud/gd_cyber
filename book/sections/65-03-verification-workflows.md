# 65.3 Verification workflows

Investigation work produces claims.

“This process ran.”

“This file was created at this time.”

“This device sent data to that address.”

A claim is useful only if it is verifiable.

Verification is the discipline of checking whether a claim is actually supported by evidence, rather than supported by a tool’s default assumptions.

This section describes high-level verification workflows.

It focuses on three practical techniques:

cross-checking,

metadata awareness,

and triangulation.

---

## 65.3.1 Definitions (verification, cross-checking, metadata, triangulation)

**Verification** is the process of increasing confidence that a claim is correct by comparing it against evidence and by trying to falsify it.

Verification is not the same thing as certainty.

It is a process for reducing error.

**Cross-checking** is verifying a claim using an independent path.

For example, you might verify a host-based log entry by also checking a network capture or a second logging source.

**Metadata** is “data about data.”

For an artifact such as a file, metadata includes timestamps, file size, and ownership information.

For a log entry, metadata includes timestamp, source, and context.

**Triangulation** is the use of multiple sources or methods to study the same phenomenon.

In the social sciences, triangulation is described as combining several methods or sources to overcome weaknesses or biases in single-method studies. [S4]

In digital investigations, the logic is similar.

You often cannot rely on one signal.

You can often rely on several weak signals that converge.

---

## 65.3.2 Why verification is necessary

Verification is necessary because tools are imperfect.

They may have bugs.

They may parse incomplete data.

They may hide uncertainty behind a clean user interface.

Verification is also necessary because adversaries can deceive.

Logs can be deleted.

Timestamps can be altered.

Artifacts can be planted.

Even in non-adversarial troubleshooting, systems lie in predictable ways.

For example, a device with a drifting clock can make every timestamp in a log technically “wrong,” while still being internally consistent.

The National Institute of Standards and Technology (NIST) forensic techniques guide emphasizes that effective forensics involves advice about different data sources, including files, operating systems, network traffic, and applications. [S1]

This is a verification principle.

If you care about correctness, you should expect to consult multiple data sources.

---

## 65.3.3 Cross-checking workflows

Cross-checking means “do not accept a claim until it has at least one independent support.”

Independence is contextual.

Two logs generated by the same agent and stored in the same directory are not independent.

A host log and a network sensor log are closer to independent.

### A practical cross-check pattern

A field-friendly pattern is:

start with the simplest evidence,

then verify with a second source that would be difficult to fake in the same way.

For example:

If an application log claims a login occurred, cross-check the operating system’s authentication logs.

If a host claims it connected to a remote address, cross-check a firewall log or packet capture.

If a file appears in a directory listing, cross-check a file system metadata view and a hash of its contents.

### Cross-checking with cryptographic hashes

A **cryptographic hash** is a short fingerprint of a file’s contents.

If the file changes, the hash changes.

The NIST Secure Hash Standard (SHS), published as Federal Information Processing Standard (FIPS) 180-4, specifies secure hash algorithms used widely for integrity checking. [S3]

Here, “SHS” is the name of the standard.

Hashes do not prove that a file is benign.

They prove that the file you are analyzing is the same file you collected.

That is a prerequisite for meaningful verification.

### Community signal: verification failures are common

In practitioner communities, confusion often arises from differences in how tools display evidence.

For example, community discussions include cases where an operator believes evidence was deleted because it disappeared in one view, but it still exists and appears on another system.

This is a reminder that verification includes verifying your tooling assumptions, not only verifying the target system. [S5]

---

## 65.3.4 Metadata awareness

Metadata awareness means knowing what your evidence fields actually mean.

It is the discipline of asking, “what does this timestamp represent?” rather than treating a timestamp as a universal truth.

### Timestamp semantics

Files usually have multiple timestamps.

They can represent creation, modification, access, and metadata changes.

Different operating systems store and update these fields differently.

Some fields can be disabled for performance reasons.

Some fields can be rewritten by simple operations such as copying.

For this reason, you should treat file timestamps as evidence that requires interpretation, not as facts that interpret themselves.

### Time zone and format discipline

Evidence correlation is easier when timestamps share a standard representation.

Request for Comments (RFC) 3339 defines a date and time format for use in Internet protocols as a profile of the ISO 8601 standard. [S2]

ISO is short for the International Organization for Standardization.

A practical rule is to normalize timelines to Coordinated Universal Time (UTC) and to record any local offsets explicitly.

If a system’s time base is unknown, record that uncertainty.

### Log metadata and collection context

A log line is not only its text.

It also has a source, a collection method, and a storage path.

These are metadata.

If you do not record them, you may not be able to reproduce or defend your interpretation.

The NIST incident handling guide emphasizes analyzing incident-related data and determining appropriate response actions. [S6]

In practice, this requires knowing whether a log is complete, whether it is filtered, and whether it was collected after the incident began.

---

## 65.3.5 Triangulation methods (high-level)

Triangulation is what you do when no single artifact is decisive.

You assemble a picture by combining multiple partial views.

### Data triangulation

Data triangulation uses multiple sources that should reflect the same event.

For example:

A message in a chat log,

a network connection to a messaging server,

and a corresponding process execution on the device.

If all three align in time and meaning, confidence increases.

If one conflicts, you investigate the discrepancy.

### Method triangulation

Method triangulation uses multiple methods to measure the same claim.

For example:

A passive capture (reading logs),

and an active probe (querying a system state),

and a third-party reference (a service provider audit log).

Each method has different biases.

That is why triangulation works.

### Interpretation discipline

Triangulation does not mean “more evidence is always better.”

It means that evidence should converge on a claim.

If evidence diverges, that divergence is information.

It may indicate:

clock disagreement,

partial logging,

a misunderstanding of metadata,

or an adversary attempting deception.

---

## 65.3.6 Suggested figures

1) **Verification ladder**: claim → primary evidence → independent cross-check → triangulated narrative.

2) **Metadata map**: an artifact surrounded by its metadata fields and collection context.

3) **Triangulation triangle**: host evidence, network evidence, and user/application evidence, with a claim at the center.

4) **Timeline alignment**: events from multiple sources normalized to UTC with offsets and uncertainty markers.

---

## Sources

- [S1] NIST SP 800-86: *Guide to Integrating Forensic Techniques into Incident Response* (multiple data sources: files, operating systems, network traffic, applications) — https://csrc.nist.gov/pubs/sp/800/86/final
- [S2] RFC 3339: *Date and Time on the Internet: Timestamps* (standard timestamp format; ISO 8601 profile) — https://www.rfc-editor.org/rfc/rfc3339
- [S3] National Institute of Standards and Technology (NIST): *FIPS 180-4 — Secure Hash Standard (SHS)* (hash algorithm standardization for integrity checking) — https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.180-4.pdf
- [S4] Wikipedia: *Triangulation (social science)* (combining methods/sources to reduce bias and improve credibility) — https://en.wikipedia.org/wiki/Triangulation_(social_science)
- [S5] r/dfir: search results for “verify” (community examples of evidence-view and verification pitfalls) — https://old.reddit.com/r/dfir/search?q=verify&restrict_sr=on&sort=relevance&t=all
- [S6] NIST SP 800-61 Rev. 2: *Computer Security Incident Handling Guide* (incident-related data analysis and response determination) — https://csrc.nist.gov/pubs/sp/800/61/r2/final
